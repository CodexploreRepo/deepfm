{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Model Layers Guide\n",
    "\n",
    "This notebook explores the four core layers that sit on top of `FeatureEmbedding`:\n",
    "**FM**, **DNN**, **CIN**, and **Multi-Head Self-Attention**.\n",
    "Each layer consumes a different view of the embedding output and captures a different type of feature interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 0. Setup — Create a Synthetic Schema & Embeddings\n",
    "\n",
    "We'll use a small synthetic schema so this notebook runs instantly without downloading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size B=8, Fields F=6, FM dim D=16\n",
      "first_order:      torch.Size([8, 1])\n",
      "field_embeddings: torch.Size([8, 6, 16])\n",
      "flat_embeddings:  torch.Size([8, 56])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from deepfm.data.schema import FieldSchema, DatasetSchema, FeatureType\n",
    "from deepfm.models.layers.embedding import FeatureEmbedding\n",
    "\n",
    "# Define a small schema: 6 fields, mix of vocab sizes and embed dims\n",
    "fields = {\n",
    "    \"user_id\":    FieldSchema(\"user_id\",    FeatureType.SPARSE, vocabulary_size=100, embedding_dim=16),\n",
    "    \"item_id\":    FieldSchema(\"item_id\",    FeatureType.SPARSE, vocabulary_size=200, embedding_dim=16),\n",
    "    \"gender\":     FieldSchema(\"gender\",     FeatureType.SPARSE, vocabulary_size=3,   embedding_dim=4),\n",
    "    \"age\":        FieldSchema(\"age\",        FeatureType.SPARSE, vocabulary_size=8,   embedding_dim=4),\n",
    "    \"occupation\": FieldSchema(\"occupation\", FeatureType.SPARSE, vocabulary_size=22,  embedding_dim=8),\n",
    "    \"city\":       FieldSchema(\"city\",       FeatureType.SPARSE, vocabulary_size=50,  embedding_dim=8),\n",
    "}\n",
    "schema = DatasetSchema(fields=fields, label_field=\"label\")\n",
    "FM_DIM = 16\n",
    "\n",
    "# Build embedding layer and get the three outputs\n",
    "emb = FeatureEmbedding(schema, fm_embed_dim=FM_DIM)\n",
    "emb.eval()\n",
    "\n",
    "batch = {\n",
    "    \"user_id\":    torch.randint(1, 100, (8,)),\n",
    "    \"item_id\":    torch.randint(1, 200, (8,)),\n",
    "    \"gender\":     torch.randint(1, 3,   (8,)),\n",
    "    \"age\":        torch.randint(1, 8,   (8,)),\n",
    "    \"occupation\": torch.randint(1, 22,  (8,)),\n",
    "    \"city\":       torch.randint(1, 50,  (8,)),\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    first_order, field_embeddings, flat_embeddings = emb(batch)\n",
    "\n",
    "B = field_embeddings.size(0)\n",
    "F = field_embeddings.size(1)\n",
    "D = field_embeddings.size(2)\n",
    "\n",
    "print(f\"Batch size B={B}, Fields F={F}, FM dim D={D}\")\n",
    "print(f\"first_order:      {first_order.shape}\")\n",
    "print(f\"field_embeddings: {field_embeddings.shape}\")\n",
    "print(f\"flat_embeddings:  {flat_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. FM Interaction Layer\n",
    "\n",
    "The FM layer computes **second-order feature interactions** efficiently in O(F*D) using the identity:\n",
    "\n",
    "```\n",
    "sum_{i<j} <v_i, v_j> = 0.5 * ( (sum_i v_i)^2 - sum_i (v_i^2) )\n",
    "```\n",
    "\n",
    "This avoids the O(F^2 * D) cost of explicit pairwise dot products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMInteraction()\n",
      "\n",
      "Parameters: 0 (none — FM is parameter-free!)\n"
     ]
    }
   ],
   "source": [
    "from deepfm.models.layers.fm import FMInteraction\n",
    "\n",
    "fm = FMInteraction()\n",
    "print(fm)\n",
    "print(f\"\\nParameters: {sum(p.numel() for p in fm.parameters())} (none — FM is parameter-free!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  field_embeddings torch.Size([8, 6, 16])  — (B, F, D)\n",
      "Output: fm_output        torch.Size([8, 1])         — (B, 1)\n",
      "\n",
      "FM interaction values (one scalar per sample):\n",
      "tensor([-0.2719, -0.4070, -0.3825, -0.7346, -0.6332,  0.6506, -0.5905,  0.0814])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    fm_output = fm(field_embeddings)\n",
    "\n",
    "print(f\"Input:  field_embeddings {field_embeddings.shape}  — (B, F, D)\")\n",
    "print(f\"Output: fm_output        {fm_output.shape}         — (B, 1)\")\n",
    "print(f\"\\nFM interaction values (one scalar per sample):\")\n",
    "print(fm_output.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Verifying the Math\n",
    "\n",
    "Let's confirm the efficient formula matches the explicit pairwise computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient vs Explicit (should match):\n",
      "  Max difference: 1.79e-07\n",
      "  All close:      True\n"
     ]
    }
   ],
   "source": [
    "# Explicit O(F^2) pairwise computation for verification\n",
    "with torch.no_grad():\n",
    "    explicit = torch.zeros(B, 1)\n",
    "    for i in range(F):\n",
    "        for j in range(i + 1, F):\n",
    "            dot = (field_embeddings[:, i] * field_embeddings[:, j]).sum(dim=1, keepdim=True)\n",
    "            explicit += dot\n",
    "\n",
    "print(\"Efficient vs Explicit (should match):\")\n",
    "print(f\"  Max difference: {(fm_output - explicit).abs().max().item():.2e}\")\n",
    "print(f\"  All close:      {torch.allclose(fm_output, explicit, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. DNN Layer\n",
    "\n",
    "The DNN is a standard MLP that processes the **flat concatenated embeddings**.\n",
    "It captures arbitrary higher-order interactions through non-linear transformations.\n",
    "\n",
    "Stack: `Linear → (BatchNorm) → Activation → Dropout` repeated per hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=56, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Output dim: 32\n"
     ]
    }
   ],
   "source": [
    "from deepfm.models.layers.dnn import DNN\n",
    "\n",
    "input_dim = flat_embeddings.shape[1]\n",
    "dnn = DNN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_units=[128, 64, 32],\n",
    "    activation=\"relu\",\n",
    "    dropout=0.1,\n",
    "    use_batch_norm=True,\n",
    ")\n",
    "print(dnn)\n",
    "print(f\"\\nOutput dim: {dnn.output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  flat_embeddings torch.Size([8, 56])  — (B, total_dim)\n",
      "Output: dnn_output      torch.Size([8, 32])       — (B, last_hidden)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dnn.eval()\n",
    "    dnn_output = dnn(flat_embeddings)\n",
    "\n",
    "print(f\"Input:  flat_embeddings {flat_embeddings.shape}  — (B, total_dim)\")\n",
    "print(f\"Output: dnn_output      {dnn_output.shape}       — (B, last_hidden)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Layer-by-Layer Dimension Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DNN parameters: 18,080\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>layer</th>\n",
       "      <th>detail</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Linear</td>\n",
       "      <td>56 -&gt; 128</td>\n",
       "      <td>7296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>features=128</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>p=0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Linear</td>\n",
       "      <td>128 -&gt; 64</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>features=64</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>p=0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Linear</td>\n",
       "      <td>64 -&gt; 32</td>\n",
       "      <td>2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>features=32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>p=0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx        layer        detail  params\n",
       "0     0       Linear     56 -> 128    7296\n",
       "1     1  BatchNorm1d  features=128     256\n",
       "2     2         ReLU             -       0\n",
       "3     3      Dropout         p=0.1       0\n",
       "4     4       Linear     128 -> 64    8256\n",
       "5     5  BatchNorm1d   features=64     128\n",
       "6     6         ReLU             -       0\n",
       "7     7      Dropout         p=0.1       0\n",
       "8     8       Linear      64 -> 32    2080\n",
       "9     9  BatchNorm1d   features=32      64\n",
       "10   10         ReLU             -       0\n",
       "11   11      Dropout         p=0.1       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for i, module in enumerate(dnn.mlp):\n",
    "    name = module.__class__.__name__\n",
    "    params = sum(p.numel() for p in module.parameters())\n",
    "    if hasattr(module, \"in_features\"):\n",
    "        detail = f\"{module.in_features} -> {module.out_features}\"\n",
    "    elif hasattr(module, \"num_features\"):\n",
    "        detail = f\"features={module.num_features}\"\n",
    "    elif hasattr(module, \"p\"):\n",
    "        detail = f\"p={module.p}\"\n",
    "    else:\n",
    "        detail = \"-\"\n",
    "    rows.append({\"idx\": i, \"layer\": name, \"detail\": detail, \"params\": params})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Total DNN parameters: {sum(p.numel() for p in dnn.parameters()):,}\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Comparing Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>output_mean</th>\n",
       "      <th>output_std</th>\n",
       "      <th>pct_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>48.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gelu</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation output_mean output_std pct_zero\n",
       "0        relu      0.0416     0.0552    48.0%\n",
       "1  leaky_relu      0.0463     0.0625     0.0%\n",
       "2        gelu      0.0162     0.0370     0.0%\n",
       "3        tanh     -0.0045     0.1195     0.0%"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for act_name in [\"relu\", \"leaky_relu\", \"gelu\", \"tanh\"]:\n",
    "    d = DNN(input_dim, [64, 32], activation=act_name, dropout=0.0, use_batch_norm=False)\n",
    "    d.eval()\n",
    "    with torch.no_grad():\n",
    "        out = d(flat_embeddings)\n",
    "    rows.append({\n",
    "        \"activation\": act_name,\n",
    "        \"output_mean\": f\"{out.mean().item():.4f}\",\n",
    "        \"output_std\": f\"{out.std().item():.4f}\",\n",
    "        \"pct_zero\": f\"{(out == 0).float().mean().item():.1%}\",\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. CIN Layer (Compressed Interaction Network)\n",
    "\n",
    "CIN is the key innovation in **xDeepFM**. It captures **explicit, vector-wise** higher-order interactions\n",
    "(unlike FM which is scalar-wise, and DNN which is implicit).\n",
    "\n",
    "Each CIN layer:\n",
    "1. Computes an outer product between the current hidden state and the original input\n",
    "2. Compresses with Conv1d (kernel_size=1) — like a learned weighted sum of interaction maps\n",
    "3. Optionally splits: half feeds forward, half goes to the output pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv1d(36, 128, kernel_size=(1,), stride=(1,))\n",
      "    (1): Conv1d(384, 128, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "\n",
      "Output dim: 192\n"
     ]
    }
   ],
   "source": [
    "from deepfm.models.layers.cin import CIN\n",
    "\n",
    "cin = CIN(num_fields=F, embed_dim=D, layer_sizes=[128, 128], split_half=True)\n",
    "print(cin)\n",
    "print(f\"\\nOutput dim: {cin.output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  field_embeddings torch.Size([8, 6, 16])  — (B, F, D)\n",
      "Output: cin_output       torch.Size([8, 192])       — (B, output_dim)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cin_output = cin(field_embeddings)\n",
    "\n",
    "print(f\"Input:  field_embeddings {field_embeddings.shape}  — (B, F, D)\")\n",
    "print(f\"Output: cin_output       {cin_output.shape}       — (B, output_dim)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Understanding split_half\n",
    "\n",
    "With `split_half=True`, each intermediate layer splits its feature maps:\n",
    "- One half feeds into the **next** CIN layer (for deeper interactions)\n",
    "- The other half goes directly to the **output pool** (for shallower interactions)\n",
    "\n",
    "This gives the model multi-granularity: the output contains both 2nd-order and higher-order interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With split_half=True, output_dim = 192 = 64 + 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>conv_in_channels</th>\n",
       "      <th>conv_out_channels</th>\n",
       "      <th>to_output_pool</th>\n",
       "      <th>to_next_layer</th>\n",
       "      <th>interaction_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer  conv_in_channels  conv_out_channels  to_output_pool  to_next_layer  \\\n",
       "0      0                36                128              64             64   \n",
       "1      1               384                128             128            128   \n",
       "\n",
       "   interaction_order  \n",
       "0                  2  \n",
       "1                  3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (conv, ds, ns) in enumerate(zip(cin.conv_layers, cin.direct_sizes, cin.next_sizes)):\n",
    "    rows.append({\n",
    "        \"layer\": i,\n",
    "        \"conv_in_channels\": conv.in_channels,\n",
    "        \"conv_out_channels\": conv.out_channels,\n",
    "        \"to_output_pool\": ds,\n",
    "        \"to_next_layer\": ns,\n",
    "        \"interaction_order\": i + 2,  # layer 0 = 2nd order, layer 1 = 3rd order, etc.\n",
    "    })\n",
    "\n",
    "print(f\"With split_half=True, output_dim = {cin.output_dim} = {' + '.join(str(d) for d in cin.direct_sizes)}\")\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Effect of split_half on Output Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [True, False]:\n",
    "    c = CIN(num_fields=F, embed_dim=D, layer_sizes=[128, 128], split_half=split)\n",
    "    with torch.no_grad():\n",
    "        out = c(field_embeddings)\n",
    "    params = sum(p.numel() for p in c.parameters())\n",
    "    print(f\"split_half={str(split):5s}  output_dim={c.output_dim:4d}  output_shape={out.shape}  params={params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Multi-Head Self-Attention Layer\n",
    "\n",
    "The attention layer refines field embeddings by learning **which field pairs matter most**.\n",
    "Used in **AttentionDeepFM** to replace or augment FM's uniform pairwise interactions.\n",
    "\n",
    "Standard transformer-style: Q/K/V projections → scaled dot-product → multi-head → residual + LayerNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiHeadSelfAttention(\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x _AttentionBlock(\n",
      "      (W_q): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (W_k): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (W_v): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (W_out): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 8,672\n"
     ]
    }
   ],
   "source": [
    "from deepfm.models.layers.attention import MultiHeadSelfAttention\n",
    "\n",
    "attn = MultiHeadSelfAttention(\n",
    "    embed_dim=D,\n",
    "    num_heads=4,\n",
    "    attention_dim=64,\n",
    "    num_layers=2,\n",
    "    use_residual=True,\n",
    ")\n",
    "print(attn)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in attn.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  field_embeddings torch.Size([8, 6, 16])  — (B, F, D)\n",
      "Output: attn_output      torch.Size([8, 6, 16])      — (B, F, D)  (same shape!)\n",
      "\n",
      "Attention preserves the (B, F, D) shape — it refines embeddings, not reduces them.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    attn.eval()\n",
    "    attn_output = attn(field_embeddings)\n",
    "\n",
    "print(f\"Input:  field_embeddings {field_embeddings.shape}  — (B, F, D)\")\n",
    "print(f\"Output: attn_output      {attn_output.shape}      — (B, F, D)  (same shape!)\")\n",
    "print(f\"\\nAttention preserves the (B, F, D) shape — it refines embeddings, not reduces them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### Visualizing Attention Weights\n",
    "\n",
    "Let's extract the attention weights from the first layer to see which fields attend to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (head 0, sample 0):\n",
      "                   user_id     item_id      gender         age  occupation        city\n",
      "user_id              0.167       0.168       0.163       0.169       0.164       0.170\n",
      "item_id              0.167       0.168       0.162       0.168       0.163       0.172\n",
      "gender               0.166       0.169       0.164       0.165       0.164       0.172\n",
      "age                  0.168       0.167       0.162       0.169       0.163       0.172\n",
      "occupation           0.168       0.167       0.164       0.169       0.163       0.168\n",
      "city                 0.167       0.167       0.164       0.168       0.163       0.171\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Manually extract attention weights from the first layer, first head\n",
    "block = attn.layers[0]\n",
    "with torch.no_grad():\n",
    "    Q = block.W_q(field_embeddings)  # (B, F, attn_dim)\n",
    "    K = block.W_k(field_embeddings)\n",
    "    head_dim = block.head_dim\n",
    "    num_heads = block.num_heads\n",
    "\n",
    "    # Reshape to multi-head\n",
    "    Q = Q.view(B, F, num_heads, head_dim).transpose(1, 2)  # (B, H, F, hd)\n",
    "    K = K.view(B, F, num_heads, head_dim).transpose(1, 2)\n",
    "\n",
    "    # Attention weights for head 0, sample 0\n",
    "    scores = torch.matmul(Q[0, 0], K[0, 0].T) / math.sqrt(head_dim)  # (F, F)\n",
    "    weights = torch.softmax(scores, dim=-1)\n",
    "\n",
    "field_names = list(schema.fields.keys())\n",
    "print(\"Attention weights (head 0, sample 0):\")\n",
    "print(f\"{'':15s}\", \"  \".join(f\"{n:>10s}\" for n in field_names))\n",
    "for i, name in enumerate(field_names):\n",
    "    row = \"  \".join(f\"{weights[i, j].item():10.3f}\" for j in range(F))\n",
    "    print(f\"{name:15s} {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "### Residual Connection Effect\n",
    "\n",
    "With `use_residual=True`, the output is `LayerNorm(attention_out + input)`. This means\n",
    "the model can learn to pass through the original embeddings when attention isn't helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative change from input:\n",
      "  With residual:    4.3467\n",
      "  Without residual: 1.2193\n",
      "\n",
      "Residual connections keep outputs closer to the input (easier to train).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    attn_res = MultiHeadSelfAttention(D, num_heads=4, attention_dim=64, num_layers=1, use_residual=True)\n",
    "    attn_no_res = MultiHeadSelfAttention(D, num_heads=4, attention_dim=64, num_layers=1, use_residual=False)\n",
    "    attn_res.eval()\n",
    "    attn_no_res.eval()\n",
    "\n",
    "    out_res = attn_res(field_embeddings)\n",
    "    out_no_res = attn_no_res(field_embeddings)\n",
    "\n",
    "    # How much does the output differ from input?\n",
    "    diff_res = (out_res - field_embeddings).norm() / field_embeddings.norm()\n",
    "    diff_no_res = (out_no_res - field_embeddings).norm() / field_embeddings.norm()\n",
    "\n",
    "print(f\"Relative change from input:\")\n",
    "print(f\"  With residual:    {diff_res.item():.4f}\")\n",
    "print(f\"  Without residual: {diff_no_res.item():.4f}\")\n",
    "print(f\"\\nResidual connections keep outputs closer to the input (easier to train).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparing All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>input</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>params</th>\n",
       "      <th>used_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FMInteraction</td>\n",
       "      <td>field_embeddings (B,F,D)</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>2nd-order, explicit</td>\n",
       "      <td>0</td>\n",
       "      <td>DeepFM, AttentionDeepFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNN</td>\n",
       "      <td>flat_embeddings (B,total_dim)</td>\n",
       "      <td>(8, 32)</td>\n",
       "      <td>higher-order, implicit</td>\n",
       "      <td>18080</td>\n",
       "      <td>DeepFM, xDeepFM, AttentionDeepFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIN</td>\n",
       "      <td>field_embeddings (B,F,D)</td>\n",
       "      <td>(8, 192)</td>\n",
       "      <td>higher-order, explicit (vector-wise)</td>\n",
       "      <td>54016</td>\n",
       "      <td>xDeepFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultiHeadSelfAttention</td>\n",
       "      <td>field_embeddings (B,F,D)</td>\n",
       "      <td>(8, 6, 16)</td>\n",
       "      <td>adaptive pairwise weighting</td>\n",
       "      <td>8672</td>\n",
       "      <td>AttentionDeepFM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    layer                          input output_shape  \\\n",
       "0           FMInteraction       field_embeddings (B,F,D)       (8, 1)   \n",
       "1                     DNN  flat_embeddings (B,total_dim)      (8, 32)   \n",
       "2                     CIN       field_embeddings (B,F,D)     (8, 192)   \n",
       "3  MultiHeadSelfAttention       field_embeddings (B,F,D)   (8, 6, 16)   \n",
       "\n",
       "                       interaction_type  params  \\\n",
       "0                   2nd-order, explicit       0   \n",
       "1                higher-order, implicit   18080   \n",
       "2  higher-order, explicit (vector-wise)   54016   \n",
       "3           adaptive pairwise weighting    8672   \n",
       "\n",
       "                            used_in  \n",
       "0           DeepFM, AttentionDeepFM  \n",
       "1  DeepFM, xDeepFM, AttentionDeepFM  \n",
       "2                           xDeepFM  \n",
       "3                   AttentionDeepFM  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = [\n",
    "    {\n",
    "        \"layer\": \"FMInteraction\",\n",
    "        \"input\": \"field_embeddings (B,F,D)\",\n",
    "        \"output_shape\": str(tuple(fm_output.shape)),\n",
    "        \"interaction_type\": \"2nd-order, explicit\",\n",
    "        \"params\": sum(p.numel() for p in fm.parameters()),\n",
    "        \"used_in\": \"DeepFM, AttentionDeepFM\",\n",
    "    },\n",
    "    {\n",
    "        \"layer\": \"DNN\",\n",
    "        \"input\": \"flat_embeddings (B,total_dim)\",\n",
    "        \"output_shape\": str(tuple(dnn_output.shape)),\n",
    "        \"interaction_type\": \"higher-order, implicit\",\n",
    "        \"params\": sum(p.numel() for p in dnn.parameters()),\n",
    "        \"used_in\": \"DeepFM, xDeepFM, AttentionDeepFM\",\n",
    "    },\n",
    "    {\n",
    "        \"layer\": \"CIN\",\n",
    "        \"input\": \"field_embeddings (B,F,D)\",\n",
    "        \"output_shape\": str(tuple(cin_output.shape)),\n",
    "        \"interaction_type\": \"higher-order, explicit (vector-wise)\",\n",
    "        \"params\": sum(p.numel() for p in cin.parameters()),\n",
    "        \"used_in\": \"xDeepFM\",\n",
    "    },\n",
    "    {\n",
    "        \"layer\": \"MultiHeadSelfAttention\",\n",
    "        \"input\": \"field_embeddings (B,F,D)\",\n",
    "        \"output_shape\": str(tuple(attn_output.shape)),\n",
    "        \"interaction_type\": \"adaptive pairwise weighting\",\n",
    "        \"params\": sum(p.numel() for p in attn.parameters()),\n",
    "        \"used_in\": \"AttentionDeepFM\",\n",
    "    },\n",
    "]\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 6. How Models Compose These Layers\n",
    "\n",
    "```\n",
    "FeatureEmbedding(batch)\n",
    "    |\n",
    "    +-- first_order (B,1)\n",
    "    +-- field_embeddings (B,F,D)\n",
    "    +-- flat_embeddings (B,total_dim)\n",
    "\n",
    "\n",
    "DeepFM:                                  xDeepFM:                               AttentionDeepFM:\n",
    "  logit = first_order                      logit = first_order                    logit = first_order\n",
    "        + FM(field_emb)                          + Linear(CIN(field_emb))               + FM(field_emb)\n",
    "        + Linear(DNN(flat_emb))                  + Linear(DNN(flat_emb))                + Linear(DNN(cat(\n",
    "                                                                                            Attn(field_emb).flatten(),\n",
    "                                                                                            flat_emb)))\n",
    "\n",
    "\n",
    "Key differences:\n",
    "  - DeepFM:          FM (2nd order explicit) + DNN (higher order implicit)\n",
    "  - xDeepFM:         CIN (higher order explicit, vector-wise) + DNN (higher order implicit)\n",
    "  - AttentionDeepFM: FM + Attention-refined embeddings fed to DNN (learned interaction importance)\n",
    "```\n",
    "\n",
    "All three share the same `FeatureEmbedding` — the only difference is how they process its outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
