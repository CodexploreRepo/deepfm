{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Adapter Guide\n",
    "\n",
    "This notebook walks through how `MovieLensAdapter` loads ML-100K data,\n",
    "engineers features, splits by leave-one-out, and produces `TabularDataset`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the Adapter\n",
    "\n",
    "The adapter takes a `data_dir` and a `DataConfig`. Calling `.build()` does everything:\n",
    "load → merge → split → fit encoders → transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 98,114 samples\n",
      "Val:   943 samples\n",
      "Test:  943 samples\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import deepfm.data.movielens as mv\n",
    "importlib.reload(mv)\n",
    "\n",
    "from deepfm.config import ExperimentConfig\n",
    "from deepfm.data.movielens import MovieLensAdapter\n",
    "\n",
    "config = ExperimentConfig()\n",
    "adapter = MovieLensAdapter(config.data)\n",
    "schema, train_ds, val_ds, test_ds = adapter.build()\n",
    "\n",
    "print(f\"Train: {len(train_ds):,} samples\")\n",
    "print(f\"Val:   {len(val_ds):,} samples\")\n",
    "print(f\"Test:  {len(test_ds):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Schema\n",
    "\n",
    "The schema describes every feature — its type, vocabulary size, embedding dim, and group.\n",
    "All downstream modules (embedding layer, models) are built from this schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>group</th>\n",
       "      <th>max_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td>sparse</td>\n",
       "      <td>944</td>\n",
       "      <td>16</td>\n",
       "      <td>user</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie_id</td>\n",
       "      <td>sparse</td>\n",
       "      <td>1679</td>\n",
       "      <td>16</td>\n",
       "      <td>item</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>sparse</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>user</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>sparse</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>user</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>occupation</td>\n",
       "      <td>sparse</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>user</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zip_prefix</td>\n",
       "      <td>sparse</td>\n",
       "      <td>383</td>\n",
       "      <td>8</td>\n",
       "      <td>user</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>genres</td>\n",
       "      <td>sequence</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>item</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name      type  vocab_size  embed_dim group max_length\n",
       "0     user_id    sparse         944         16  user          -\n",
       "1    movie_id    sparse        1679         16  item          -\n",
       "2      gender    sparse           3          4  user          -\n",
       "3         age    sparse           8          4  user          -\n",
       "4  occupation    sparse          22          8  user          -\n",
       "5  zip_prefix    sparse         383          8  user          -\n",
       "6      genres  sequence          20          8  item          6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for name, field in schema.fields.items():\n",
    "    rows.append({\n",
    "        \"name\": name,\n",
    "        \"type\": field.feature_type.value,\n",
    "        \"vocab_size\": field.vocabulary_size,\n",
    "        \"embed_dim\": field.embedding_dim,\n",
    "        \"group\": field.group,\n",
    "        \"max_length\": field.max_length if field.feature_type.value == \"sequence\" else \"-\",\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total fields:         {schema.num_fields}\")\n",
    "print(f\"Sparse fields:        {len(schema.sparse_fields)}\")\n",
    "print(f\"Sequence fields:      {len(schema.sequence_fields)}\")\n",
    "print(f\"Dense fields:         {len(schema.dense_fields)}\")\n",
    "print(f\"Total embedding dim:  {schema.total_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspecting Samples\n",
    "\n",
    "Each sample from the dataset is a `(feature_dict, label)` tuple.\n",
    "Integer features become `torch.long`, the label is `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1.0\n",
      "\n",
      "Features:\n",
      "  user_id          shape=torch.Size([])  dtype=torch.int64  value=1\n",
      "  movie_id         shape=torch.Size([])  dtype=torch.int64  value=168\n",
      "  gender           shape=torch.Size([])  dtype=torch.int64  value=2\n",
      "  age              shape=torch.Size([])  dtype=torch.int64  value=2\n",
      "  occupation       shape=torch.Size([])  dtype=torch.int64  value=20\n",
      "  zip_prefix       shape=torch.Size([])  dtype=torch.int64  value=300\n",
      "  genres           shape=torch.Size([6])  dtype=torch.int64  value=tensor([5, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "features, label = train_ds[0]\n",
    "\n",
    "print(f\"Label: {label.item()}\\n\")\n",
    "print(\"Features:\")\n",
    "for name, tensor in features.items():\n",
    "    print(f\"  {name:15s}  shape={str(tensor.shape):10s}  dtype={tensor.dtype}  value={tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How Encoders Work\n",
    "\n",
    "Encoders are fitted on the **training split only**. Unknown values in val/test map to index 0 (OOV).\n",
    "Let's peek at a few encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender mapping (OOV=0):\n",
      "  {'F': 1, 'M': 2}\n",
      "  vocab_size = 3\n",
      "\n",
      "Age bucket mapping:\n",
      "  {1: 1, 18: 2, 25: 3, 35: 4, 45: 5, 50: 6, 56: 7}\n",
      "  vocab_size = 8\n",
      "\n",
      "Genres vocab_size = 20\n",
      "Genres mapping (first 5): {'Action': 1, 'Adventure': 2, 'Animation': 3, \"Children's\": 4, 'Comedy': 5}\n"
     ]
    }
   ],
   "source": [
    "# Gender encoder\n",
    "gender_enc = adapter._encoders[\"gender\"]\n",
    "print(\"Gender mapping (OOV=0):\")\n",
    "print(f\"  {gender_enc._mapping}\")\n",
    "print(f\"  vocab_size = {gender_enc.vocabulary_size}\")\n",
    "print()\n",
    "\n",
    "# Age encoder (bucketed)\n",
    "age_enc = adapter._encoders[\"age\"]\n",
    "print(\"Age bucket mapping:\")\n",
    "print(f\"  {age_enc._mapping}\")\n",
    "print(f\"  vocab_size = {age_enc.vocabulary_size}\")\n",
    "print()\n",
    "\n",
    "# Genres encoder\n",
    "genre_enc = adapter._encoders[\"genres\"]\n",
    "print(f\"Genres vocab_size = {genre_enc.vocabulary_size}\")\n",
    "print(f\"Genres mapping (first 5): {dict(list(genre_enc._mapping.items())[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Leave-One-Out Split Explained\n",
    "\n",
    "For each user with >= 3 interactions (ordered by timestamp):\n",
    "- **Last** interaction → test\n",
    "- **Second-to-last** → validation\n",
    "- **All remaining** → training\n",
    "\n",
    "Users with < 3 interactions go entirely to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val samples:  943 (one per eligible user)\n",
      "Test samples: 943 (one per eligible user)\n",
      "\n",
      "User 0 has 270 training movies\n",
      "  Val movie:  74\n",
      "  Test movie: 102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Val and test should each have exactly 1 sample per eligible user\n",
    "# (943 users in ML-100K all have >= 3 interactions)\n",
    "print(f\"Val samples:  {len(val_ds)} (one per eligible user)\")\n",
    "print(f\"Test samples: {len(test_ds)} (one per eligible user)\")\n",
    "\n",
    "# Verify no overlap: check a user's movie_id across splits\n",
    "uid_idx = 0  # first encoded user_id in each split\n",
    "train_movies = set(train_ds.features[\"movie_id\"][\n",
    "    train_ds.features[\"user_id\"] == train_ds.features[\"user_id\"][0]\n",
    "].tolist())\n",
    "val_movie = val_ds.features[\"movie_id\"][0]\n",
    "test_movie = test_ds.features[\"movie_id\"][0]\n",
    "\n",
    "print(f\"\\nUser 0 has {len(train_movies)} training movies\")\n",
    "print(f\"  Val movie:  {val_movie}\")\n",
    "print(f\"  Test movie: {test_movie}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using with DataLoader\n",
    "\n",
    "The `TabularDataset` works directly with PyTorch's `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes:\n",
      "  user_id          torch.Size([8])\n",
      "  movie_id         torch.Size([8])\n",
      "  gender           torch.Size([8])\n",
      "  age              torch.Size([8])\n",
      "  occupation       torch.Size([8])\n",
      "  zip_prefix       torch.Size([8])\n",
      "  genres           torch.Size([8, 6])\n",
      "  labels           torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "batch_features, batch_labels = next(iter(loader))\n",
    "\n",
    "print(\"Batch shapes:\")\n",
    "for name, tensor in batch_features.items():\n",
    "    print(f\"  {name:15s}  {tensor.shape}\")\n",
    "print(f\"  {'labels':15s}  {batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label distribution:\n",
      "  Positive (rating >= 4.0): 54,396 (55.4%)\n",
      "  Negative (rating <  4.0): 43,718 (44.6%)\n",
      "  Total: 98,114\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_ds.labels\n",
    "pos = (train_labels == 1).sum()\n",
    "neg = (train_labels == 0).sum()\n",
    "total = len(train_labels)\n",
    "\n",
    "print(f\"Training label distribution:\")\n",
    "print(f\"  Positive (rating >= {config.data.label_threshold}): {pos:,} ({pos/total:.1%})\")\n",
    "print(f\"  Negative (rating <  {config.data.label_threshold}): {neg:,} ({neg/total:.1%})\")\n",
    "print(f\"  Total: {total:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. User-Item Interaction Map\n",
    "\n",
    "The adapter tracks which items each user has interacted with.\n",
    "This will be used by negative sampling (step 2.3) to avoid sampling items the user has already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users tracked: 943\n",
      "Interactions per user:\n",
      "  Min:    20\n",
      "  Max:    737\n",
      "  Mean:   106.0\n",
      "  Median: 65.0\n"
     ]
    }
   ],
   "source": [
    "user_items = adapter.user_items\n",
    "\n",
    "interaction_counts = [len(items) for items in user_items.values()]\n",
    "print(f\"Total users tracked: {len(user_items)}\")\n",
    "print(f\"Interactions per user:\")\n",
    "print(f\"  Min:    {min(interaction_counts)}\")\n",
    "print(f\"  Max:    {max(interaction_counts)}\")\n",
    "print(f\"  Mean:   {np.mean(interaction_counts):.1f}\")\n",
    "print(f\"  Median: {np.median(interaction_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The `TabularDataset` is intentionally simple — it just converts numpy arrays to tensors.\n",
    "All feature engineering (encoding, splitting, negative sampling) happens upstream in the adapter.\n",
    "\n",
    "```\n",
    "Raw Data (u.data, u.user, u.item)\n",
    "    |\n",
    "    v\n",
    "MovieLensAdapter  -->  fits LabelEncoder / MultiHotEncoder on train split\n",
    "    |\n",
    "    v\n",
    "TabularDataset(features_dict, labels)  <-- one per split (train/val/test)\n",
    "    |\n",
    "    v\n",
    "DataLoader(dataset, batch_size=4096, shuffle=True)\n",
    "    |\n",
    "    v\n",
    "Model.forward(batch_features)  -->  logits\n",
    "```\n",
    "- `MovieLensAdapter`\n",
    "```\n",
    "MovieLensAdapter(DataConfig)\n",
    "    │\n",
    "    ├── _load_and_merge()     Read u.data + u.user + u.item → merged DataFrame\n",
    "    ├── _leave_one_out_split()  Per-user temporal split → train/val/test DataFrames\n",
    "    ├── _fit_encoders()       Fit LabelEncoder (×6) + MultiHotEncoder (genres) on train\n",
    "    ├── _build_schema()       Create DatasetSchema with vocab sizes from encoders\n",
    "    └── _transform()          Apply encoders → TabularDataset\n",
    "          │\n",
    "          ▼\n",
    "    (DatasetSchema, train_ds, val_ds, test_ds)\n",
    "```\n",
    "\n",
    "Next step: **Negative sampling** (step 2.3) adds synthetic negative examples to each split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
